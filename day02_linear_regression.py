import requests
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


# --- è¼‰å…¥è³‡æ–™é›† (Boston Housing Dataset from Carnegie Mellon University) ---

def get_boston_housing_data() -> pd.DataFrame:
    url = "http://lib.stat.cmu.edu/datasets/boston"
    raw = requests.get(url).text.splitlines()[22:]  # å¾ç¬¬ 23 è¡Œé–‹å§‹

    # æ¯ç­†è³‡æ–™åˆ†ç‚ºå…©è¡Œ â†’ å…± 506 ç­† â†’ ç¸½å…± 1012 è¡Œ
    data = []
    for i in range(0, len(raw), 2):
        line1 = list(map(float, raw[i].strip().split()))
        line2 = list(map(float, raw[i + 1].strip().split()))
        data.append(line1 + line2)

    col_names = [
        "CRIM",  # æ¯äººå¹³å‡çŠ¯ç½ªç‡
        "ZN",  # å€åŸŸä½å®…ç”¨åœ°æ¯”ä¾‹
        "INDUS",  # å€åŸŸéé›¶å”®å•†æ¥­ç”¨åœ°æ¯”ä¾‹
        "CHAS",  # æŸ¥çˆ¾æ–¯æ²³è™›æ“¬è®Šæ•¸ (1 = æ²³æµæ—, 0 = å…¶ä»–)
        "NOX",  # ä¸€æ°§åŒ–æ°®æ¿ƒåº¦ (parts per 10 million)
        "RM",  # æ¯å€‹ä½å®…çš„å¹³å‡æˆ¿é–“æ•¸
        "AGE",  # 1940 å¹´ä¹‹å‰å»ºé€ çš„è‡ªç”¨ä½å®…æ¯”ä¾‹
        "DIS",  # åˆ°æ³¢å£«é “äº”å€‹ä¸­å¿ƒå€åŸŸçš„åŠ æ¬Šè·é›¢
        "RAD",  # å…¬è·¯æ¥è¿‘æŒ‡æ•¸ (1 = æœ€æ¥è¿‘, 24 = æœ€é )
        "TAX",  # æ¯ $10,000 çš„è²¡ç”¢ç¨…ç‡
        "PTRATIO",  # å­¸ç”Ÿèˆ‡æ•™å¸«æ¯”ä¾‹
        "B",  # 1000(Bk - 0.63)^2, Bk = å€åŸŸé»‘äººæ¯”ä¾‹
        "LSTAT",  # å€åŸŸäººå£ä¸­ä½æ”¶å…¥è€…çš„æ¯”ä¾‹
        "MEDV",  # è‡ªç”¨ä½å®…çš„ä¸­ä½æ•¸åƒ¹æ ¼ (å–®ä½: $1000s)
    ]
    
    df = pd.DataFrame(data, columns=col_names)

    return df

original_data = get_boston_housing_data()

# --- è³‡æ–™å‰è™•ç† (ç„¡ç¼ºå¤±å€¼ï¼Œä¹Ÿæ²’æœ‰é«˜åº¦è²¢ç»æ€§çš„ç‰¹å¾µï¼Œæ‰€ä»¥ä¹Ÿä¸è™•ç†) ---

cleaned_data = original_data.copy()

# ç¼ºå¤±å€¼æª¢æŸ¥ (0 ç­†)
print(original_data.isnull().sum())

# Pearson ç›¸é—œä¿‚æ•¸æª¢æŸ¥
correlation_matrix = cleaned_data.corr()
target_corr = correlation_matrix['MEDV']
high_corr_features = target_corr[target_corr > 0.8].drop('MEDV')
print(f"èˆ‡ target é«˜åº¦æ­£ç›¸é—œçš„æ¬„ä½:", high_corr_features)

# --- ç‰¹å¾µå·¥ç¨‹ (å¿½ç•¥) ---

# --- æ¨¡å‹è¨“ç·´ ---

# è³‡æ–™åˆ†å‰²
X = cleaned_data.drop(columns=["MEDV"])
y = cleaned_data["MEDV"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# å»ºç«‹èˆ‡è¨“ç·´æ¨¡å‹
model = LinearRegression()
model.fit(X_train, y_train)

# --- è³‡æ–™é æ¸¬ ---
y_pred = model.predict(X_test)

# --- çµæœè©•ä¼° ---
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("ğŸ“ˆ æ¨¡å‹è©•ä¼°çµæœï¼š")
print(f"å‡æ–¹èª¤å·® (MSE): {mse:.4f}")
print(f"æ±ºå®šä¿‚æ•¸ RÂ²: {r2:.4f}")

# --- å›æ­¸ä¿‚æ•¸æª¢è¦– ---
coefficients = pd.DataFrame({
    "Feature": X.columns,
    "Coefficient": model.coef_
}).sort_values(by="Coefficient", key=abs, ascending=False)

print("\nğŸ“Š å„ç‰¹å¾µå›æ­¸ä¿‚æ•¸ (ä¾å½±éŸ¿åŠ›æ’åº):")
print(coefficients)

# --- æ®˜å·®åˆ†æ ---
residuals = y_test - y_pred

plt.scatter(y_pred, residuals, alpha=0.6)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted MEDV")
plt.ylabel("Residuals")
plt.title("Residual Plot")
plt.show()
